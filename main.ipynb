{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mcucii/TextToImageGeneration_StackGAN/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXmRuWBRdjuJ",
        "outputId": "d24254b0-deae-4822-f1ba-4dfd2d630932"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaIR_4PudtmL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/RIProject')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXUwtfV4dwMb"
      },
      "outputs": [],
      "source": [
        "import config as cfg\n",
        "from dataset import TextImageDataset\n",
        "from stage1 import GANTrainer_stage1\n",
        "from stage2 import GANTrainer_stage2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhOIhPNhUUJ2"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3Z6PjUKaTuH"
      },
      "outputs": [],
      "source": [
        "class Args:\n",
        "    train = 'y'\n",
        "    stage = 2\n",
        "\n",
        "if Args.stage == 1:\n",
        "    cfg.IMG_SIZE = 64\n",
        "    cfg.NET_G = ''\n",
        "    cfg.NET_D = ''\n",
        "else:\n",
        "    cfg.IMG_SIZE = 256\n",
        "    cfg.STAGE1_G = \"data_reduced/birds/Model_stage1/netG_epoch_100.pth\"\n",
        "    cfg.STAGE1_D = \"data_reduced/birds/Model_stage1/netD_epoch_100.pth\"\n",
        "\n",
        "cfg.STAGE = Args.stage\n",
        "\n",
        "if Args.train == \"y\":\n",
        "    cfg.TRAIN = True\n",
        "else:\n",
        "    cfg.NET_G = \"../data_reduced/birds/Model_stage2/netG_epoch_100.pth\"\n",
        "    cfg.NET_D = \"../data_reduced/birds/Model_stage2/netD_epoch_100.pth\"\n",
        "    cfg.TRAIN = False\n",
        "\n",
        "output_dir = '../output/birds'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddsVitDTRDV2"
      },
      "outputs": [],
      "source": [
        "def train():\n",
        "  image_transform = transforms.Compose([\n",
        "      transforms.RandomResizedCrop(cfg.IMG_SIZE),  # Randomly crop and resize the image\n",
        "      transforms.RandomHorizontalFlip(),         # Randomly flip the image horizontally\n",
        "      transforms.ColorJitter(),                  # Randomly adjust brightness, contrast, saturation, and hue\n",
        "      transforms.ToTensor(),                     # Convert the image to a PyTorch tensor\n",
        "      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize the image\n",
        "  ])\n",
        "  dataset = TextImageDataset(cfg.DATA_DIR, 'train', input_transform=image_transform)\n",
        "  dataset_size = len(dataset)\n",
        "  #print(f\"Veličina skupa podataka: {dataset_size}\")\n",
        "\n",
        "  dataloader = DataLoader(dataset, batch_size=cfg.TRAIN_BATCH_SIZE, drop_last=True, shuffle=False, num_workers=2)\n",
        "  batch_size = dataloader.batch_size\n",
        "  #print(f\"Veličina batch-a: {batch_size}\")\n",
        "\n",
        "  num_batches_per_epoch = len(dataloader)\n",
        "  #print(f\"Broj batch-eva po epohi: {num_batches_per_epoch}\")\n",
        "\n",
        "  if Args.stage == 1:\n",
        "    trainer = GANTrainer_stage1(output_dir)\n",
        "  else:\n",
        "    trainer = GANTrainer_stage2(output_dir)\n",
        "\n",
        "  trainer.train(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqMVmWdsRLSD"
      },
      "outputs": [],
      "source": [
        "def test():\n",
        "  # TODO\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-e2VLo2HcCto"
      },
      "outputs": [],
      "source": [
        "\n",
        "def main():\n",
        "\n",
        "  if Args.train == 0:\n",
        "    cfg.TRAIN = False  # True by default (train)\n",
        "    # todo: test\n",
        "    #cfg.NET_G = \"?\"  # NET_G -> pre-trained model:\n",
        "  else:\n",
        "    cfg.TRAIN = True\n",
        "\n",
        "  if Args.stage == 1:\n",
        "    cfg.IMG_SIZE = 64\n",
        "    cfg.STAGE = 1\n",
        "  else :\n",
        "    cfg.IMG_SIZE = 256\n",
        "    cfg.STAGE = 2\n",
        "\n",
        "  output_dir = '../output/birds'\n",
        "\n",
        "\n",
        "  if cfg.TRAIN:\n",
        "    train()\n",
        "  # else:\n",
        "  #   test()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAogAIgN8CXF",
        "outputId": "bee69abb-9944-46fe-ac36-fbd542e665c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load from:  data_reduced/birds/Model_stage1/netG_epoch_100.pth\n",
            "Stage2_Discriminator(\n",
            "  (encode_img): Sequential(\n",
            "    (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (2): Conv2d(96, 192, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (5): Conv2d(192, 384, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (6): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (8): Conv2d(384, 768, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (9): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (11): Conv2d(768, 1536, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (12): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (13): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (14): Conv2d(1536, 3072, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (15): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (17): Conv2d(3072, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (18): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (20): Conv2d(1536, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (21): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (embed_fc): Linear(in_features=128, out_features=12288, bias=True)\n",
            "  (embed_bn): BatchNorm1d(12288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (fc): Sequential(\n",
            "    (0): Conv2d(1536, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (3): Conv2d(768, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "    (4): Sigmoid()\n",
            "  )\n",
            ")\n",
            "Save G/D models\n"
          ]
        }
      ],
      "source": [
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nNU0WRqA59T"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM6n9bCLNK5BpfLvPpbuQQQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}